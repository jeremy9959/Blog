{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization\n",
    "\n",
    "### Introduction\n",
    "I've had a lot of trouble finding a comprehensible explanation of expectation maximization, even in simple cases like those that arise when trying to reconstruct haplotype frequencies from phenotypes.  So here is my attempt.\n",
    "\n",
    "The relevant situation is when you have some observed data which derives from hidden data and you have a statistical model, depending on some parameters, that predicts the hidden data and hence the observed.  You'd like\n",
    "to estimate the parameters of the model using only the observed data.\n",
    "\n",
    "This situation comes up, for example, with hidden Markov models, but an even simpler situation is the fairly typical problem from genetics that is\n",
    "discussed in [this post](https://jeremy9959.github.io/Excoffier-Slatkin).  That post considers the situation\n",
    "in which you have two loci, each of which has two alleles, so that there are four haplotypes possible.\n",
    "Looking at an individual, you can observe each locus separately but you can't directly observe the haplotypes.\n",
    "So for example, an individual with phenotype AaBb could have haplotype AB/ab or Ab/aB.  If one assumes a model where the two loci are independent and mating is random -- so that phenotypes are found by choosing a pair of haplotypes from the pool at random -- one can use EM to estimate the most likely haplotype frequencies.\n",
    "\n",
    "Using likelihood ratios one could go further and test the model to see how well it fits the observed data.\n",
    "\n",
    "### Setup\n",
    "\n",
    "We assume that we have a random variable $X$ depending on a statistical model with parameters $\\theta$.\n",
    "We assume further that there is an additional random variable $Z$, also depending on $\\theta$, that we cannot observe\n",
    "directly, but which in some way is connected to the values of $X$.  We'd like to find the maximum likelihood estimate for $\\theta$ given observations of $X$.\n",
    "\n",
    "Having observed $x_1,\\ldots, x_N$, we consider the log-likelihood of $\\theta$ \n",
    "$$\n",
    "\\ell(\\theta)=\\log P(\\{x_{i}\\}|\\theta)=\\sum_{i=1}^{N}\\log P(x_{i}|\\theta)\n",
    "$$\n",
    "where we've implicitly assumed an uninformative prior on $\\theta$ and that the $x_i$ are chosen $iid$.\n",
    "\n",
    "We assume that the $x_i$ are derived from the hidden $Z$ so\n",
    "$$\n",
    "P(x_i|\\theta)=\\sum_{\\alpha} P(x_i,z=\\alpha|theta)\n",
    "$$\n",
    "where we've recovered $P(x|\\theta)$ by integrating out the possible values of $z$.\n",
    "So purely formally we have\n",
    "$$\n",
    "\\ell(\\theta)=\\sum_{i=1}^{N}\\log\\sum_{\\alpha}P(x_i,z=\\alpha|\\theta).\n",
    "$$\n",
    "\n",
    "#### Jensen's Inequality\n",
    "\n",
    "Theorem: \n",
    "Let $\\phi$ be a convex function on the real line and let $X$ be an integrable real-valued random variable on a probability space $\\Omega$.  Then $E[\\phi(X)]\\ge \\phi(E[X])$.  If $\\phi$ is strictly convex, then equality holds only if $X$ is ae constant.\n",
    "\n",
    "Notice that $-\\log(x)$ is strictly convex, so in particular\n",
    "$$\n",
    "-\\frac{1}{m}\\sum_{i=1}^{m}\\log(x_i)\\ge -\\log(\\frac{1}{m}\\sum_{i=1}^{m} x_{i})\n",
    "$$\n",
    "which says that the geometric mean is less than the arithmetic mean, so in some sense Jensen's inequality is a vast generalization of that fact.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
