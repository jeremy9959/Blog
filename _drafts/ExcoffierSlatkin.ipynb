{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Haplotypes\n",
    "\n",
    "Some notes on the classic paper\n",
    "\n",
    "[Excoffier, M. and Slatkin, L. Maximum-Likelihood Estimation of Molecular Haplotype Frequencies in a Diploid Population. Mol. Biol. Evol. 12(5):921-927 (1995)](http://www.uvm.edu/~rsingle/stat380/F04/possible/Excoffier+slatkin-MolBiolEvol-1995.pdf)\n",
    "\n",
    "Suppose we have two loci, each of which has potential genotype at that locus of  $0,1,2$ representing the number of \"reference\" alleles.  An individual can have one of nine combined genotypes depending on the situation at each locus.\n",
    "\n",
    "One can ask a more refined question: what are the underlying haplotypes?  If the individual is, say, of type $22$ then it must be the case that each chromosome is of type $11$.  But if the individual is of type $11$\n",
    "then there are two possibilities: $(10,01)$ or $(00,11)$.  \n",
    "\n",
    "This question is of interest because one might want to know if the sites are independent of one another or if there is non-trivial linkage between them.\n",
    "\n",
    "More generally, if there are $n$ loci in a diploid individual, there are $3^n$ possible combinations of genotypes.  Although it is somewhat of an abuse of language, we follow the language of the paper above and call such a combination a phenotype.  Phenotypes are indexed by vectors of $n$ integers between $0$ and $2$.\n",
    "\n",
    "We have $2^n$ haplotypes obtained by choosing either the reference or alternate allele at each of the n sites,\n",
    "so haplotypes are indexed by vectors of $n$ integers between $0$ and $1$.  The phenotype associated with a pair\n",
    "$\\alpha$ and $\\beta$ of haplotypes corresponds to the vector sum $\\alpha+\\beta$.  If a phenotype has a zero or a two at a particular location, then that determines the possible haplotypes at that location.  If the phenotype has a $1$, then at that location there are two possibilities.  As a result, the number of ways that a phenotype\n",
    "can be decomposed into a sum of haplotypes (taking symmetry into account) is $2^(s-1)$ where $s$ is the number of $1$'s in the phenotype (or $1$ if that number is zero).\n",
    "\n",
    "### EM algorithm\n",
    "\n",
    "We're given counts of each of the $3^n$ phenotypes and we want to give the maximum likelihood estimate of the haplotype frequencies under the assumption that there is no linkage between them.  \n",
    "\n",
    "Let's  consider the case where $n=2$ so that there are $9$ phenotypes and $4$ haplotypes.   The data consists of counts $N_{ij}$ over the nine phenotypes (so $i$ and $j$ are between $0$ and $2$ inclusive). Let $N$ be the sum of the $N_{ij}$. \n",
    "\n",
    "We choose initial (prior) estimates for the haplotype frequencies $p_{ij}^{(0)}$ (where here $i$ and $j$ are between $0$ and $1$.)\n",
    "\n",
    "In light of the phenotype data, we find the expected number of times each haplotype occurs assuming the\n",
    "haplotype frequency estimates.  In most cases, the phenotype determines the haplotypes, so that\n",
    "for example phenotype $22$ contributes two copies of haplotype $11$ and phenotype $12$ contributes\n",
    "$1$ copy of haplotype $01$ and one copy of haplotype $11$.  The only exception is phenotype $11$, which\n",
    "is made up of either haplotype $00$ and haplotype $11$ or haplotype $10$ and haplotype $01$.  So among\n",
    "the observed number of individuals with phenotype $11$, how many come from each haplotype?  Given\n",
    "the estimated haplotype frequencies, we can compute the expected fractions as\n",
    "$$\n",
    "E(10,01)=\\frac{p_{10}p_{01}}{p_{01}p_{10}+p_{00}p_{11}}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "E(00,11)=\\frac{p_{00}p_{11}}{p_{01}p_{10}+p_{00}p_{11}}.\n",
    "$$\n",
    "\n",
    "Putting this information together we can compute the estimated number of times each haplotype appears given the data.  Dividing by the total number of chromosomes, we get the expected frequency of each haplotype assuming\n",
    "the data and the prior estimates. \n",
    "\n",
    "Now we view these frequencies as the maximum likelihood estimate of the true probabilities given the \"expected\" data.  Now we put those frequencies back through the process to refine them further. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p00,p01,p10,p11=.25,.25,.25,.25\n",
    "a,b=.5,.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = np.array([2,1,0,1,a,0,0,0,0,0,0,0,1,b,0,2,1,0,0,1,0,0,b,1,0,0,0,0,0,2,0,a,1,0,1,2]).reshape((4,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=p00*p11/(p00*p11+p10*p01)\n",
    "b=p10*p01/(p00*p11+p10*p01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=binom(2,.8).rvs(1000)\n",
    "G=binom(2,.6).rvs(1000)\n",
    "H=list(zip(F,G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in H:\n",
    "    n[x]=n[x]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(2, 1): 340,\n",
       "         (1, 1): 158,\n",
       "         (1, 0): 51,\n",
       "         (2, 2): 219,\n",
       "         (1, 2): 98,\n",
       "         (2, 0): 97,\n",
       "         (0, 2): 17,\n",
       "         (0, 1): 17,\n",
       "         (0, 0): 3})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "V=np.array([3,51,97,17,158,340,17,98,219])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "newT=np.dot(N,V)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0765, 0.114 , 0.235 , 0.5745])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
